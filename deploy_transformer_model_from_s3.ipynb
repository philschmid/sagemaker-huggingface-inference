{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automotive-destiny",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker-sdk - Deploy ðŸ¤— Transformers for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-frost",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Deploy a trained Hugging Face Transformer model on to SageMaker for inference](#Deploy-a-trained-Hugging-Face-Transformer-model-on-to-SageMaker-for-inference)  \n",
    "    a. [Deploy the model directly after training](#Deploy-the-model-directly-after-training)  \n",
    "    b. [Deploy the model using `model_data`](#Deploy-the-model-using-model_data)  \n",
    "3. [Deploy one of the 10 000+ Hugging Face Transformers to Amazon SageMaker for Inference](#Deploy-one-of-the-10-000+-Hugging-Face-Transformers-to-Amazon-SageMaker-for-Inference)   \n",
    "\n",
    "\n",
    "Welcome to this getting started guide, we will use the new Hugging Face Inference DLCs and Amazon SageMaker Python SDK to deploy two transformer model for inference. \n",
    "In the first example we deploy a trained Hugging Face Transformer model on to SageMaker for inference.\n",
    "In the second example we directly deploy one of the 10 000+ Hugging Face Transformers from the [Hub](https://huggingface.co/models) to Amazon SageMaker for Inference.\n",
    "\n",
    "You can find the documentation for the inference solution [here](add link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatal-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare\n",
    "pytorch_cpu_image_uri=\"801740330924.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.7.1-transformers4.6.1-cpu-py36-ubuntu18.04\"\n",
    "!pip install git+https://github.com/icywang86rui/sagemaker-python-sdk.git@hf-inference --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-correlation",
   "metadata": {},
   "source": [
    "## Deploy a Hugging Face Transformer model from S3 to SageMaker for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polar-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-us-east-1-558105141721/sagemaker-huggingface-serving/models/model.tar.gz\",  # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   image_uri=pytorch_cpu_image_uri, # Beta DLC image uri\n",
    "   #transformers_version=\"4.6\", # transformers version used\n",
    "   #pytorch_version=\"1.7\", # pytorch version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# example request, you always need to define \"inputs\"\n",
    "data = {\n",
    "   \"inputs\": \"The new Hugging Face SageMaker DLC makes it super easy to deploy models in production. I love it!\"\n",
    "}\n",
    "\n",
    "# request\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compliant-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "other-hurricane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tmp_model/tokenizer_config.json',\n",
       " './tmp_model/special_tokens_map.json',\n",
       " './tmp_model/vocab.txt',\n",
       " './tmp_model/added_tokens.json',\n",
       " './tmp_model/tokenizer.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "model.save_pretrained('./tmp_model')\n",
    "tokenizer.save_pretrained('./tmp_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "saved-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python archive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "soviet-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-artwork",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
